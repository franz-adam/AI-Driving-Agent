{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwRj3ZATBnBf"
      },
      "source": [
        "# OpenAI CarRacing with Behavioral Cloning\n",
        "\n",
        "In this homework, you will train an agent to drive on a race track in a video-game style simulator. The agent has a neural network controller that you will train using example data of a car racing around the track. At each timestep, the neural network takes in the *state* of the car as an image and outputs which *action* to take. \n",
        "\n",
        "This system is known as a *Markov Decision Process (MDP)* because at each discrete timestep, the agent makes a decision using only the current state, with no memory of the previous state (this is called Markov property). In the context of Reinforcement Learning, this training strategy is known as *behavioral cloning* because we are learning by copying the actions of another agent.\n",
        "\n",
        "The simulator is the CarRacing-v0 environment from OpenAI. In this environment, a *state* is a (96,96,3) color image which shows the position of the car along with the current speed, stearing position, and braking status in the bottom of the image. The *actions* that are available to the agent are stear (between -1 and 1), accelerate (0 to 1), and break (0 to 1). To simplify this assignment, I have converted this into a classification problem with only seven discrete actions:\n",
        "\n",
        "0. Do nothing\n",
        "1. Left\n",
        "2. Left+Break\n",
        "3. Right\n",
        "4. Right+Break\n",
        "5. Accelerate!\n",
        "6. Break\n",
        "\n",
        "Below is provided a dataset of 11,132 example (state, action) pairs you can use for training. These were sampled from simulations of a highly-skilled AI agent. The first cell downloads the data and installs many of the dependencies needed to run the simulations and generate videos in Google Colab. You should be able to train your agent and view videos of your agent within Colab.\n",
        "\n",
        "## Tasks:\n",
        "1.   Create a class called `Agent` with methods 'train' and 'act'.\n",
        "2.   Train the agent to drive. Optimize hyperparameters such as the learning rate, network architecture, etc. You can do this by hand (you don't need to do anything fancy).\n",
        "3. Create a video of your agent driving.\n",
        "\n",
        "## To turn in:\n",
        "1. Your code as a jupyter notebook.\n",
        "2. A description of your agent model and its performance. Include this description after your code in the jupyter notebook, following the [Guide to Describing ML Methods](https://laulima.hawaii.edu/access/content/group/MAN.XLSIDIN35ps.202230/Guide_to_Describing_ML_Methods.pdf). I don't expect you to do extensive hyperparameter tuning, but you **must** describe the performance of your model on a validation set using the appropriate metrics so that you know when you are overfitting.\n",
        "3. Upload a video of your best agent to [this google drive](https://drive.google.com/drive/folders/1Hk4PTqfr5A3BeW2m3mgAuQmbxo_Z-8AK?usp=sharing). (Feel free to also upload any funny or interesting behavior.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WycAuNU2JX1"
      },
      "outputs": [],
      "source": [
        "# NO NEED TO MODIFY THIS CELL\n",
        "# Dependencies for rendering openai gym in colab and enable video recording.\n",
        "# Remove \" > /dev/null 2>&1\" to see what is going on under the hood\n",
        "!pip install gym[box2d] pyvirtualdisplay piglet > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
        "import gym\n",
        "from gym import logger as gymlogger\n",
        "gymlogger.set_level(40) #error only\n",
        "from gym.wrappers import Monitor\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random, math, glob, io, base64\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython.display import HTML\n",
        "from IPython import display as ipythondisplay\n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "\n",
        "def show_video():\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")\n",
        "    \n",
        "def wrap_env(env):\n",
        "  \"\"\"\n",
        "  Utility functions to enable video recording of gym environment and displaying it\n",
        "  To enable video, just do \"env = wrap_env(env)\"\"\n",
        "  \"\"\"\n",
        "  return Monitor(env, './video', force=True)\n",
        "\n",
        "# Download example data for training.\n",
        "import gzip, os, pickle, random\n",
        "import matplotlib.pyplot as plt\n",
        "!gdown --id 1AQnMFSRU3qQcHA-ruS8Ahcz-00FmYoi0 # File shared on Peter's gdrive 6MB.\n",
        "with gzip.open('carracing_behavior.gzip', 'rb') as f:\n",
        "    states, action_classes = pickle.load(f)\n",
        "\n",
        "print('\\nState data shape (examples, x, y, color):', states.shape)\n",
        "print('Action data shape (examples, action idx):', action_classes.shape)\n",
        "\n",
        "# Plot an example state. This is the model input.\n",
        "print('\\nExample state (this is the input to your neural network):')\n",
        "plt.imshow(states[0, :, :, :])\n",
        "\n",
        "# The simulator expects a length-3 array corresponding to stear, \n",
        "# accellerate, and break. But I converted the training data actions into a \n",
        "# discrete set to frame the problem as classification. This is the set of \n",
        "# possible actions. The indices in training data targets (action_classes) \n",
        "# correspond to this set of actions. Your agent's act method should\n",
        "# return one of these, not an integer index.\n",
        "\n",
        "ACTION_SPACE = [[0, 0, 0],  # no action\n",
        "                [-1, 0, 0],  # left\n",
        "                [-1, 0, 1],  # left+break\n",
        "                [1, 0, 0],  # right\n",
        "                [1, 0, 1],  # right+break\n",
        "                [0, 1, 0],  # acceleration\n",
        "                [0, 0, 1], ]  # break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSG302fDI7JC"
      },
      "source": [
        "# Create, Train, and Simulate Agent\n",
        "\n",
        "Create your agent class below. The code provided should help get you started. Then test your agent in the racing environment.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import keras\n",
        "from gc import callbacks\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "0IkR48OGHdc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode and reshape actions\n",
        "\n",
        "ohe = OneHotEncoder()\n",
        "y = action_classes\n",
        "y = y.reshape(-1, 1)\n",
        "y = ohe.fit_transform(y).toarray()"
      ],
      "metadata": {
        "id": "F_0AAqFnKL55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent():\n",
        "  def __init__(self):\n",
        "    self.action_space = ACTION_SPACE\n",
        "    self.train_states = states.reshape(states.shape[0], 96*96*3)\n",
        "    self.train_action = y\n",
        "\n",
        "  def train(self):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(32, input_dim=(96*96*3), activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(7, activation='softmax'))\n",
        "\n",
        "    opt = SGD(learning_rate=1e-6, momentum=0.8)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "    callbacks = [EarlyStopping(patience=6, monitor = 'val_loss')]\n",
        "    model.fit(self.train_states, self.train_action, epochs=100, batch_size=32, validation_split=0.15, callbacks = callbacks)\n",
        "    \n",
        "    self.model = model\n",
        "\n",
        "  def act(self, input):\n",
        "    input = input.reshape(-1, 96*96*3) \n",
        "    return self.action_space[np.argmax(self.model.predict(input))]\n",
        "\n",
        "agent = Agent()\n",
        "agent.train()"
      ],
      "metadata": {
        "id": "R_Mn0Q9L-WPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvWPN5uI4LQg"
      },
      "source": [
        "# Simulate Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLj3USuFM6Lf"
      },
      "outputs": [],
      "source": [
        "# NO NEED TO MODIFY THIS CELL\n",
        "# Run simulation for t timesteps.\n",
        "NUM_TIMESTEPS = 1000  # Increase this to run simulation longer.\n",
        "with wrap_env(gym.make(\"CarRacing-v0\")) as env: # Exits env when done.\n",
        "  observation = env.reset()  # Restarts car at the starting line.\n",
        "  for t in range(NUM_TIMESTEPS):\n",
        "    env.render() \n",
        "    action = agent.act(observation)\n",
        "    observation, reward, done, info = env.step(action)\n",
        "    if done:\n",
        "      print(\"Episode finished after {} timesteps\".format(t+1))\n",
        "      break\n",
        "show_video()  # Video can be downloaded by clicking option in bottom right."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Description of Agent Model\n",
        "\n",
        "1. I am trying to train a neural network agent to drive on a race track in a 2D video-game style simulator. The input is image data with dimensions (96,96,3) and the goal is to produce the correct (output) action to take. This is a classification problem with 7 different outputs for the agent (brake, accelerate, left, right, ..).\n",
        "\n",
        "2. Our training data comes from the output of a highly skilled AI agent, image by image. It consists of states (images of the car, the track and it's position) and the actions that the AI agent took.\n",
        "\n",
        "3. I am using a fully connected neural network with 4 layers, linear rectified unit activation functions for hidden layers, softmax activation for the output layer, categorical crossentropy for the loss function and stochastic gradient descent for the optimizer. I chose the activation function as a result of parameter tuning, the loss function based on my research as what to use for classificaiton problems and the architecture and optimizer based on me wanting to replicate my attempt of building this kind of network without libraries. For this network, I am utilizing Keras.\n",
        "\n",
        "4. Data was given to us cleaned and structured. I only needed to reshape the states and reshape and one-hot encode the actions. \n",
        "\n",
        "5. The total dataset contained 11132 examples that were then randomly divided into two subsets: 85% training and 15% validation. The network was trained on the training set, while the validation set was used for early stopping and hyperparameter optimization.\n",
        "\n",
        "6. I optimized the hyperparameters in the neural network by hand and used the validation-loss for EarlyStopping as the deciding factor. For the network architecture I tried these number of neurons for the layers (except output layer), 32,64,128. For the activation functions I tried Sigmoid, tanh and ReLu. \n",
        "For the training process I adjusted learning rate, momentum and batch size. with following values\n",
        "lr: (1e-4, 1e-5, 1e-6, 1e-7)\n",
        "momentum: (0.5, 0.8, 1)\n",
        "batch size: (16, 32, 64)\n",
        "\n",
        "7. I exhaustively tried every combination of parameters for the network architecture (number of neurones and activation function) and then did the same for the training parameters with the already chosen architectural model. The model with the lowest validation loss was chosen.\n",
        "\n",
        "8. The model achieved an validation loss of 1.3 and accuracy of about 62% on the 15% held out validation set. \n",
        "\n",
        "9. There does not seem to be an obvious difference between test and train data when we assume that the AI agent was indeed highly skilled and could have driven on-track infinitely long. "
      ],
      "metadata": {
        "id": "lCwk103V7odD"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "HW5_OpenAI_CarRacer.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}